{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.productboard.com/wp-content/uploads/2019/11/screen-shot-2019-11-07-at-4-18-51-pm.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation -- Estimate Individualized Responses to Incentives\n",
    "\n",
    "Nowadays, business decision makers rely on estimating the causal effect of interventions to answer what-if questions about shifts in strategy, such as promoting specific product with discount, adding new features to a website or increasing investment from a sales team. However, rather than learning whether to take action for a specific intervention for all users, people are increasingly interested in understanding the different responses from different users to the two alternatives. Identifying the characteristics of users having the strongest response for the intervention could help make rules to segment the future users into different groups. This can help optimize the policy to use the least resources and get the most profit.\n",
    "\n",
    "In this case study, we will use a personalized pricing example to explain how the [EconML](https://aka.ms/econml) library could fit into this problem and provide robust and reliable causal solutions.\n",
    "\n",
    "### Summary\n",
    "\n",
    "1. [Background](#background)\n",
    "2. [Data](#data)\n",
    "3. [Get Causal Effects with EconML](#estimate)\n",
    "4. [Understand Treatment Effects with EconML](#interpret)\n",
    "5. [Make Policy Decisions with EconML](#policy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background <a id=\"background\"></a>\n",
    "\n",
    "<img src=\"https://cdn.pixabay.com/photo/2018/08/16/11/59/radio-3610287_960_720.png\" width=\"400\" />\n",
    "\n",
    "The global online media market is growing fast over the years. Media companies are always interested in attracting more users into the market and encouraging them to buy more songs or become members. In this example, we'll consider a scenario where one experiment a media company is running is to give small discount (10%, 20% or 0) to their current users based on their income level in order to boost the likelihood of their purchase. The goal is to understand the **heterogeneous price elasticity of demand** for people with different income level, learning which users would respond most strongly to a small discount. Furthermore, their end goal is to make sure that despite decreasing the price for some consumers, the demand is raised enough to boost the overall revenue.\n",
    "\n",
    "EconMLâ€™s `DMLCateEstimator` based estimators can be used to take the discount variation in existing data, along with a rich set of user features, to estimate heterogeneous price sensitivities that vary with multiple customer features. Then, the `SingleTreeCateInterpreter` provides a presentation-ready summary of the key features that explain the biggest differences in responsiveness to a discount, and the `SingleTreePolicyInterpreter` recommends a policy on who should receive a discount in order to increase revenue (not only demand), which could help the company to set an optimal price for those users in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports to get us started\n",
    "# Utilities\n",
    "import os\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generic ML imports\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# EconML imports\n",
    "from econml.dml import LinearDMLCateEstimator, ForestDMLCateEstimator\n",
    "from econml.cate_interpreter import SingleTreeCateInterpreter, SingleTreePolicyInterpreter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data <a id=\"data\"></a>\n",
    "\n",
    "\n",
    "The dataset* has ~10,000 observations and includes 9 continuous and categorical variables that represent user's characteristics and online behaviour history such as age, log income, previous purchase, previous online time per week, etc. \n",
    "\n",
    "We define the following variables:\n",
    "\n",
    "Feature Name|Type|Details \n",
    ":--- |:---|:--- \n",
    "**account_age** |W| user's account age\n",
    "**age** |W|user's age\n",
    "**avg_hours** |W| the average hours user was online per week in the past\n",
    "**days_visited** |W| the average number of days user visited the website per week in the past\n",
    "**friend_count** |W| number of friends user connected in the account \n",
    "**has_membership** |W| whether the user had membership\n",
    "**is_US** |W| whether the user accesses the website from the US \n",
    "**songs_purchased** |W| the average songs user purchased per week in the past\n",
    "**income** |X| user's income\n",
    "**price** |T| the price user was exposed during the discount season (baseline price * samll discount)\n",
    "**demand** |Y| songs user purchased during the discount season\n",
    "\n",
    "**To protect the privacy of the company, we use the simulated data as an example here. The data is synthetically generated and the feature distributions don't correspond to real distributions. However, the feature names have preserved their names and meaning.*\n",
    "\n",
    "\n",
    "The treatment and outcome are generated using the following functions:\n",
    "$$\n",
    "T = \n",
    "\\begin{cases}\n",
    "  1 & \\text{with } p=0.2,  \\\\\n",
    "  0.9 & \\text{with }p=0.3, & \\text{if income}<1 \\\\\n",
    "  0.8 & \\text{with }p=0.5, \\\\\n",
    "  \\\\\n",
    "    1 & \\text{with }p=0.7, \\\\\n",
    "  0.9 & \\text{with }p=0.2, & \\text{if income}\\ge1 \\\\\n",
    "  0.8 & \\text{with }p=0.1, \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\gamma(X) & = -3 - 14 \\cdot \\{\\text{income}<1\\} \\\\\n",
    "\\beta(X,W) & = 20 + 0.5 \\cdot \\text{avg_hours} + 5 \\cdot \\{\\text{days_visited}>4\\} \\\\\n",
    "Y &= \\gamma(X) \\cdot T + \\beta(X,W)\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sample pricing data\n",
    "file_url = \"https://msalicedatapublic.blob.core.windows.net/datasets/Pricing/pricing_sample.csv\"\n",
    "train_data = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_age</th>\n",
       "      <th>age</th>\n",
       "      <th>avg_hours</th>\n",
       "      <th>days_visited</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>has_membership</th>\n",
       "      <th>is_US</th>\n",
       "      <th>songs_purchased</th>\n",
       "      <th>income</th>\n",
       "      <th>price</th>\n",
       "      <th>demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>1.834234</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.903237</td>\n",
       "      <td>0.960863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.917117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>7.171411</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.330161</td>\n",
       "      <td>0.732487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.585706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>5.351920</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.036203</td>\n",
       "      <td>1.130937</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.675960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>6.723551</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.911926</td>\n",
       "      <td>0.929197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.361776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>2.448247</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.148967</td>\n",
       "      <td>0.533527</td>\n",
       "      <td>0.8</td>\n",
       "      <td>12.624123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_age  age  avg_hours  days_visited  friends_count  has_membership  \\\n",
       "0            3   53   1.834234             2              8               1   \n",
       "1            5   54   7.171411             7              9               0   \n",
       "2            3   33   5.351920             6              9               0   \n",
       "3            2   34   6.723551             0              8               0   \n",
       "4            4   30   2.448247             5              8               1   \n",
       "\n",
       "   is_US  songs_purchased    income  price     demand  \n",
       "0      1         4.903237  0.960863    1.0   3.917117  \n",
       "1      1         3.330161  0.732487    1.0  11.585706  \n",
       "2      1         3.036203  1.130937    1.0  24.675960  \n",
       "3      1         7.911926  0.929197    1.0   6.361776  \n",
       "4      0         7.148967  0.533527    0.8  12.624123  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data sample\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define estimator inputs\n",
    "Y = train_data[\"demand\"]  # outcome of interest\n",
    "T = train_data[\"price\"]  # intervention, or treatment\n",
    "X = train_data[[\"income\"]]  # features\n",
    "W = train_data.drop(columns=[\"demand\", \"price\", \"income\"])  # confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test data\n",
    "X_test = np.linspace(0, 5, 100).reshape(-1, 1)\n",
    "X_test_data = pd.DataFrame(X_test, columns=[\"income\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Causal Effects with EconML <a id=\"estimate\"></a>\n",
    "To learn the price elasticity on demand as a function of income, we fit the model as follows:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "log(Y) & = \\theta(X) \\cdot log(T) + f(X,W) + \\epsilon \\\\\n",
    "log(T) & = g(X,W) + \\eta\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "where $\\epsilon, \\eta$ are uncorrelated error terms. \n",
    "\n",
    "The models we fit here aren't an exact match for the data generation function above, but if they are a good approximation, they will allow us to create a good discount policy.  Although the model is misspecified, we hope to see that our `DMLCateEstimator` based estimators can still capture the right trend of $\\theta(X)$ and that the recommended policy beats other baseline policies (such as always giving a discount) on revenue.  Because of the mismatch between the data generating process and the model we're fitting, there isn't a single true $\\theta(X)$ (the true elasticity varies with not only X but also T and W), but given how we generate the data above, we can still calculate the range of true $\\theta(X)$ to compare against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define underlying treatment effect function given DGP\n",
    "def gamma_fn(X):\n",
    "    return -3 - 14 * (X[\"income\"] < 1)\n",
    "\n",
    "def beta_fn(X):\n",
    "    return 20 + 0.5 * (X[\"avg_hours\"]) + 5 * (X[\"days_visited\"] > 4)\n",
    "\n",
    "def demand_fn(data, T):\n",
    "    Y = gamma_fn(data) * T + beta_fn(data)\n",
    "    return Y\n",
    "\n",
    "def true_te(x, n, stats):\n",
    "    if x < 1:\n",
    "        subdata = train_data[train_data[\"income\"] < 1].sample(n=n, replace=True)\n",
    "    else:\n",
    "        subdata = train_data[train_data[\"income\"] >= 1].sample(n=n, replace=True)\n",
    "    te_array = subdata[\"price\"] * gamma_fn(subdata) / (subdata[\"demand\"])\n",
    "    if stats == \"mean\":\n",
    "        return np.mean(te_array)\n",
    "    elif stats == \"median\":\n",
    "        return np.median(te_array)\n",
    "    elif isinstance(stats, int):\n",
    "        return np.percentile(te_array, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the estimate and range of true treatment effect\n",
    "truth_te_estimate = np.apply_along_axis(true_te, 1, X_test, 1000, \"mean\")  # estimate\n",
    "truth_te_upper = np.apply_along_axis(true_te, 1, X_test, 1000, 95)  # upper level\n",
    "truth_te_lower = np.apply_along_axis(true_te, 1, X_test, 1000, 5)  # lower level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric heterogeneity (work required)\n",
    "First of all, we can try to learn a **linear projection of the treatment effect** assuming a polynomial form of $\\theta(X)$. We use the `LinearDMLCateEstimator` estimator. Since we don't have any priors on these models, we use a generic gradient boosting tree estimators to learn the expected price and demand from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get log_T and log_Y\n",
    "log_T = np.log(T)\n",
    "log_Y = np.log(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train EconML model\n",
    "est = \"your code here\"\n",
    "est.fit(\"your code here\")\n",
    "# Get treatment effect and its confidence interval\n",
    "te_pred = est.effect(X_test)\n",
    "te_pred_interval = est.effect_interval(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the estimate and the truth\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X_test.flatten(), te_pred, label=\"Sales Elasticity Prediction\")\n",
    "plt.plot(X_test.flatten(), truth_te_estimate, \"--\", label=\"True Elasticity\")\n",
    "plt.fill_between(\n",
    "    X_test.flatten(),\n",
    "    te_pred_interval[0],\n",
    "    te_pred_interval[1],\n",
    "    alpha=0.2,\n",
    "    label=\"90% Confidence Interval\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    X_test.flatten(),\n",
    "    truth_te_lower,\n",
    "    truth_te_upper,\n",
    "    alpha=0.2,\n",
    "    label=\"True Elasticity Range\",\n",
    ")\n",
    "plt.xlabel(\"Income\")\n",
    "plt.ylabel(\"Songs Sales Elasticity\")\n",
    "plt.title(\"Songs Sales Elasticity vs Income\")\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, it's clear to see that the true treatment effect is a **nonlinear** function of income, with elasticity around -1.75 when income is smaller than 1 and a small negative value when income is larger than 1. The model fits a quadratic treatment effect, which is not a great fit. But it still captures the overall trend: the elasticity is negative and people are less sensitive to the price change if they have higher income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final coefficient and intercept summary\n",
    "est.summary(feat_name=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LinearDMLCateEstimator` estimator can also return the summary of the coefficients and intercept for the final model, including point estimates, p-values and confidence intervals. From the table above, we notice that $income$ has positive effect and ${income}^2$ has negative effect, and both of them are statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonparametric Heterogeneity (work required)\n",
    "Since we already know the true treatment effect function is nonlinear, let us fit another model using `ForestDMLCateEstimator`, which assumes a fully **nonparametric estimation of the treatment effect**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train EconML model\n",
    "est = \"your code here\"\n",
    "\n",
    "est.fit(\"your code here\")\n",
    "# Get treatment effect and its confidence interval\n",
    "te_pred = est.effect(X_test)\n",
    "te_pred_interval = est.effect_interval(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the estimate and the truth\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X_test.flatten(), te_pred, label=\"Sales Elasticity Prediction\")\n",
    "plt.plot(X_test.flatten(), truth_te_estimate, \"--\", label=\"True Elasticity\")\n",
    "plt.fill_between(\n",
    "    X_test.flatten(),\n",
    "    te_pred_interval[0],\n",
    "    te_pred_interval[1],\n",
    "    alpha=0.2,\n",
    "    label=\"90% Confidence Interval\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    X_test.flatten(),\n",
    "    truth_te_lower,\n",
    "    truth_te_upper,\n",
    "    alpha=0.2,\n",
    "    label=\"True Elasticity Range\",\n",
    ")\n",
    "plt.xlabel(\"Income\")\n",
    "plt.ylabel(\"Songs Sales Elasticity\")\n",
    "plt.title(\"Songs Sales Elasticity vs Income\")\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that this model fits much better than the `LinearDMLCateEstimator`, the 90% confidence interval correctly covers the true treatment effect estimate and captures the variation when income is around 1. Overall, the model shows that people with low income are much more sensitive to the price changes than higher income people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Treatment Effects with EconML (work required) <a id=\"interpret\"></a>\n",
    "EconML includes interpretability tools to better understand treatment effects. Treatment effects can be complex, but oftentimes we are interested in simple rules that can differentiate between users who respond positively, users who remain neutral and users who respond negatively to the proposed changes.\n",
    "\n",
    "The EconML `SingleTreeCateInterpreter` provides interperetability by training a single decision tree on the treatment effects outputted by the any of the EconML estimators. In the figure below we can see in dark red users respond strongly to the discount and the in white users respond lightly to the discount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrp = SingleTreeCateInterpreter(\"your code here\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Policy Decision with EconML (work required) <a id=\"policy\"></a>\n",
    "We want to make policy decisions to maximum the **revenue** instead of the demand. In this scenario,\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "Rev & = Y \\cdot T \\\\\n",
    "    & = \\exp^{log(Y)} \\cdot T\\\\\n",
    "    & = \\exp^{(\\theta(X) \\cdot log(T) + f(X,W) + \\epsilon)} \\cdot T \\\\\n",
    "    & = \\exp^{(f(X,W) + \\epsilon)} \\cdot T^{(\\theta(X)+1)}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "With the decrease of price, revenue will increase only if $\\theta(X)+1<0$. Thus, we set `sample_treatment_cast=-1` here to learn **what kinds of customers we should give a small discount to maximum the revenue**.\n",
    "\n",
    "The EconML library includes policy interpretability tools such as `SingleTreePolicyInterpreter` that take in a treatment cost and the treatment effects to learn simple rules about which customers to target profitably. In the figure below we can see the model recommends to give discount for people with income less than $0.985$ and give original price for the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intrp = SingleTreePolicyInterpreter(\"your code here\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us compare our policy with other baseline policies! Our model says which customers to give a small discount to, and for this experiment, we will set a discount level of 10% for those users. Because the model is misspecified we would not expect good results with large discounts. Here, because we know the ground truth, we can evaluate the value of this policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to compute revenue\n",
    "def revenue_fn(data, discount_level1, discount_level2, baseline_T, policy):\n",
    "    policy_price = baseline_T * (1 - discount_level1) * policy + baseline_T * (1 - discount_level2) * (1 - policy)\n",
    "    demand = demand_fn(data, policy_price)\n",
    "    rev = demand * policy_price\n",
    "    return rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_dic = {}\n",
    "# our policy above\n",
    "policy = intrp.treat(X)\n",
    "policy_dic[\"Our Policy\"] = np.mean(revenue_fn(train_data, 0, 0.1, 1, policy))\n",
    "\n",
    "## previous strategy\n",
    "policy_dic[\"Previous Strategy\"] = np.mean(train_data[\"price\"] * train_data[\"demand\"])\n",
    "\n",
    "## give everyone discount\n",
    "policy_dic[\"Give Everyone Discount\"] = np.mean(revenue_fn(train_data, 0.1, 0, 1, np.ones(len(X))))\n",
    "\n",
    "## don't give discount\n",
    "policy_dic[\"Give No One Discount\"] = np.mean(revenue_fn(train_data, 0, 0.1, 1, np.ones(len(X))))\n",
    "\n",
    "## follow our policy, but give -10% discount for the group doesn't recommend to give discount\n",
    "policy_dic[\"Our Policy + Give Negative Discount for No-Discount Group\"] = np.mean(revenue_fn(train_data, -0.1, 0.1, 1, policy))\n",
    "\n",
    "## give everyone -10% discount\n",
    "policy_dic[\"Give Everyone Negative Discount\"] = np.mean(revenue_fn(train_data, -0.1, 0, 1, np.ones(len(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get policy summary table\n",
    "res = pd.DataFrame.from_dict(policy_dic, orient=\"index\", columns=[\"Revenue\"])\n",
    "res[\"Rank\"] = res[\"Revenue\"].rank(ascending=False)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We beat the baseline policies!** Our policy gets the highest revenue except for the one raising the price for the No-Discount group. That means our currently baseline price is low, but the way we segment the user does help increase the revenue!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
